<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shiyao Xu (å¾è¯—ç‘¶)'s Homepage</title>
  <meta name="author" content="Shiyao Xu">
  <meta name="description" content="Shiyao Xu's Homepage">
  <meta name="keywords" content="Shiyao Xu,å¾è¯—ç‘¶,homepage,computer vision,human motion,vlm">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ¥º</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shiyao Xu (å¾è¯—ç‘¶)</name>
              </p>
              <p style="text-align:center">
                Email: xsy9915[at]gmail.com/shiyao.xu[at]unitn.it &nbsp;&nbsp;<a href="https://github.com/41xu">Github</a>&nbsp;&nbsp;<a href="paper/ShiyaoXU_CV_JAN_2025.pdf">CV</a>&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=uK8FvBQAAAAJ">Google Scholar</a>&nbsp;&nbsp;<a href="https://twitter.com/xusy2333">Twitter</a>&nbsp;&nbsp;<a href="https://www.linkedin.com/in/shiyao-xu-784102173/">Linkedin</a>&nbsp;&nbsp;<a href="https://www.zhihu.com/people/zhuo-ji-dui-chang">çŸ¥ä¹</a>
              </p>
              <p>
                <!-- I am Shiyao Xu (å¾è¯—ç‘¶), currently a research assistant at Tsinghua University, <a href="http://www.liuyebin.com/">Prof. Yebin Liu</a>'s group. I also work closely with <a href="https://is.mpg.de/~vabrevaya">Victoria Fernandez Abrevaya </a> in MPI-IS, <a href="https://lingzhili.com/">Lingzhi Li</a> and <a href="https://lishen-shirley.github.io/">Dr. Li Shen</a> in DAMO Academy, Alibaba Group.
                My research interests lie in generation models, 3D avatar generation and neural rendering. -->
                <!-- I am Shiyao Xu (å¾è¯—ç‘¶), currently a research scientist at <a href="https://cybever.ai">Cybever Inc</a>. My research interests lie in 3D-aware understanding, editing, and generation, and also neural rendering. -->
                I am Shiyao Xu (å¾è¯—ç‘¶), a 1st-year ELLIS PhD student at the Center for Mind and Brain (<a href="https://www.cimec.unitn.it/">CIMeC</a>) and <a href="https://mhug.disi.unitn.it/">MHUG</a> group of University of Trento, supervised by <a href="https://paolorota.github.io/">Prof. Paolo Rota</a>, co-supervised by <a href="https://gulvarol.github.io/">Prof. GÃ¼l Varol(ENPC)</a>. 
                My research interests lie in human-centric 3D-aware understanding and generation, specifically about vision language models for human motion understandingğŸ’ƒğŸ½ğŸ•ºğŸ».
                <br>
                <br>
                I'm fortunate to work with <a href="https://junlinhan.github.io/">Junlin Han</a>, <a href="https://lingzhili.com/">Lingzhi Li</a>, <a href="https://lishen-shirley.github.io/">Dr. Li Shen</a>, <a href="https://www.wict.pku.edu.cn/zlian/">Prof. Zhouhui Lian</a> in my pervious experience.
                <!-- I also worked with <a href="http://www.liuyebin.com/">Prof. Yebin Liu</a>, <a href="https://zhanghongwen.cn/">Prof. Hongwen Zhang</a>, <a href="https://lingzhili.com/">Lingzhi Li</a>, <a href="https://lishen-shirley.github.io/">Dr. Li Shen</a>, <a href="https://www.wict.pku.edu.cn/zlian/">Prof. Zhouhui Lian</a>. -->
                <!-- I am Shiyao Xu (å¾è¯—ç‘¶), currently a research assistant at Tsinghua University, <a href="http://www.liuyebin.com/">Prof. Yebin Liu</a>'s group. I also work closely with <a href="https://lingzhili.com/">Lingzhi Li</a> and <a href="https://lishen-shirley.github.io/">Dr. Li Shen</a> in DAMO Academy, Alibaba Group.
                <br>
                My research interests lie in 3D-aware stylization, generation and neural rendering. -->
              </p>

              <p>
                I obtain my M.Sc. degree from <a href="https://www.pku.edu.cn/">Peking University</a>, China, 2023, supervised by <a href="https://www.wict.pku.edu.cn/zlian/">Prof. Zhouhui Lian</a>, and bachelor at <a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>, China, 2020.
              </p>
              <!-- <p>
                I'm now an incoming Ph.D. in <a href="https://team.inria.fr/mimetic/">MimeTIC research team</a> at <a href="https://www.inria.fr/en">Inria</a>, France, working with <a href="https://boukhayma.github.io/">Adnane Boukhayma</a> and <a href="https://is.mpg.de/~vabrevaya">Victoria FernÃ¡ndez Abrevaya</a>. 
              </p> -->
              <!-- <p>
                <strong><font color=red>I'm looking for a PhD position.</font></strong> Please freely contact me! :)
              </p> -->
          
              <!-- <p>
                My research interests lie in neural rendering and generation models.
              </p> -->
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <!-- <a href="images/Shiyao_Xu_Cartoon.PNG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Shiyao_Xu_Cartoon.PNG" class="hoverZoomLink"></a> -->
              <a href="images/ShiyaoXU.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ShiyaoXU.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News!ğŸ”¥</heading>
            <li>2025.05: We launch the 1st workshop on <a href="https://i-hfm-2025.github.io/I-HFM-2025/">Interactive Human-centric Foundation Models</a> at ICCV 2025 in Hawaii! come and submit your work! </li>
            <li>2025.04: I'll attend ICVSS 2025 this summer, see you in Sicily!!ğŸï¸ğŸ˜</li>
            <!-- <li>2025.01: Won a grant from The European High-Performance Computing Joint Undertaking! Thanks EuroHPC and the team!!</li> -->
            <!-- <li>2025.01: Thank you Italian Super Computing Resource for supporting my research!</li> -->
            <li>2024.10: FD-3DGS got rejected after several submissions...ğŸ˜¥ Fine, life'll also encounter the same thing.ğŸ¥²</li>
            <li>2024.09: Finally!!! I ended my industry experience at some startup and moved to Trento, Italy, to start my PhD journey!ğŸ‡®ğŸ‡¹</li>
            <!-- <li>2023.06: Join <a href="http://www.liuyebin.com/">Prof. Yebin Liu</a>'s group at Tsinghua University as a Research Assistant.</li> -->
            <li>2023.07-08: Serve as volunteer(Teaching Assistant and Research Assistant) in <a href="https://sgi.mit.edu/">SGI(Summer Gemoetry Initiative) 2023</a>.</li>
            <li>2023.04: FINALLY! Our paper: <i>DeSRF: Deformable Stylized Radiance Field</i> is accepted by CVPR 2023 Workshop: <a href="https://generative-vision.github.io/workshop-CVPR-23/">Generative Models for Computer Vision</a>. See you in Vancouver, Canada (if my visa is approved)!</li>
            <li>2022.10: Recieve a graduate school scholarshipğŸ’°!</li>
            <li>2022.08: Happy to announce that our paper "Your3dEmoji" is accepted by SIGGRAPH ASIA 2022 Tech. Comm.!ğŸ¤ª See you in Korea!</li>
          </td>
          </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <a href="images/4-teaser.png"><img style="width:100%;max-width:100%" alt="cybever" src="images/4-teaser.png" class="hoverZoomLink"></a>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>FD-3DGS: Flexible Disentangled 3DGS for Scenes Understanding and Manipulation</papertitle>
              <br>
              <strong><a href="https://xusy2333.com">Shiyao Xu</a></strong>, <a href="https://junlinhan.github.io/">Junlin Han</a>, Jie Yang.
              <br>
              <em>got rejected by some conferenceğŸ¥²it's ok, both life and research will encounter some rejectionsğŸ¥¹. you can see it below.</em>
              <br>
              <a href="paper/FD-3DGS.pdf">[PDF]</a>
              <br>
              <p>We propose FD-3DGS to distill the semantic information into 3D Gaussians and directly manipulate 3D Gaussians using language.</p>
          </td>
      </tr>

          <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                  <source src='images/3-teaser.mov'>
                </video>              
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>DeSRF: Deformable Stylized Radiance Field</papertitle>
              <br>
              <strong><a href="https://xusy2333.com">Shiyao Xu</a></strong>, <a href="https://lingzhili.com/">Lingzhi Li</a>,  <a href="https://scholar.google.co.uk/citations?user=ABbCaxsAAAAJ&hl=en">Li Shen</a>, <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>CVPRW 2023, CVPR Workshop on <a href="https://generative-vision.github.io/workshop-CVPR-23/">Generative Models for Computer Vision</a></em>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/html/Xu_DeSRF_Deformable_Stylized_Radiance_Field_CVPRW_2023_paper.html">[Project]</a>
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/html/Xu_DeSRF_Deformable_Stylized_Radiance_Field_CVPRW_2023_paper.html">[PDF]</a>
              <a href=".">[Code](tbc)</a>
              <a href="images/GCV17_poster.pdf">[Poster]</a>
              <br>
              <p>We propose a more efficient method, <strong>DeSRF</strong>, to stylize the radiance field, which also transfers style information to the geometry according to the input style.</p>
          </td>
      </tr>

          
          <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                  <source src='images/2-teaser.mov'>
                </video>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Your3dEmoji: Creating Personalized Emojis via One-shot 3D-aware Cartoon Avatar Synthesis</papertitle>
              <br>
              <strong><a href="https://xusy2333.com">Shiyao Xu</a></strong>, <a href="https://lingzhili.com/">Lingzhi Li</a>,  <a href="https://scholar.google.co.uk/citations?user=ABbCaxsAAAAJ&hl=en">Li Shen</a>, <a href="https://menyifang.github.io/">Yifang Men</a>, <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em><strong>SIGGRAPH ASIA 2022</strong> Technical Communication</em>
              <br>
              <a href=".">[Project](tbc)</a>
              <a href="paper/Your3dEmoji.pdf">[PDF]</a>
              <a href="https://dl.acm.org/doi/10.1145/3550340.3564220">[DOI]</a>
              <a href="https://github.com/41xu/Your3dEmoji">[Code]</a>
              <br>
              <p>We propose a novel 3D generative model to translate a real-world face image into its corresponding 3D avatar with only a single style example provided. Our model is 3D-aware in sense and also able to do attribute editing, such as smile, age, etc directly in the 3D domain.</p>
          </td>
      </tr>
          
        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                  <source src='images/1-teaser.mp4'>
                </video>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Dynamic Texture Transfer using PatchMatch and Transformers</papertitle>
              <br>
              Guo Pu, <strong><a href="https://xusy2333.com">Shiyao Xu</a></strong>, Xixin Cao, <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <a href="https://arxiv.org/pdf/2402.00606.pdf">[PDF]</a> <i> finally available on arxiv... but this is my first project;-)</i>
              <p>We propose an automatically method to transfer the dynamic texture of a given video to a still image.</p>
              <details>
                <summary>Abstract</summary>
                <ol>
                How to automatically transfer the dynamic texture of a given video to the target still image is a challenging and ongoing problem. 
                In this paper, we propose to handle this task via a simple yet effective model that utilizes both PatchMatch and Transformers. 
                The key idea is to decompose the task of dynamic texture transfer into two stages, where the start frame of the target video with the desired dynamic texture is synthesized in the first stage via a distance map guided texture transfer module based on the PatchMatch algorithm. 
                Then, in the second stage, the synthesized image is decomposed into structure-agnostic patches, according to which their corresponding subsequent patches can be predicted by exploiting the powerful capability of Transformers equipped with VQ-VAE for processing long discrete sequences. 
                After getting all those patches, we apply a Gaussian weighted average merging strat- egy to smoothly assemble them into each frame of the target stylized video. Experimental results demonstrate the effectiveness and superiority of the proposed method in dynamic texture transfer compared to the state of the art.
                </ol>
              </details>
          </td>
      </tr>
      </tbody></table> 



      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Working Experiences</heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/mathmagic.jpg"><img style="width:50%;max-width:50%" alt="cybever" src="images/mathmagic.jpg" class="hoverZoomLink"></a>
        </td>
        <td width="75%" valign="center">
          <p><strong>2024.07 - 2024.09: 3D Algorithm Engineer</strong> at Math Magic.</p>
          </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/cybever.png"><img style="width:50%;max-width:50%" alt="cybever" src="images/cybever.png" class="hoverZoomLink"></a>
        </td>
        <td width="75%" valign="center">
          <p><strong>2023.07 - 2024.05: Research Scientist</strong> at <a href="https://cybever.ai">Cybever Inc.</a>, Mountain View (remotely).</p>
          </td>
      </tr>

      <!-- <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/thu.png"><img style="width:100%;max-width:100%" alt="thu" src="images/thu.png" class="hoverZoomLink"></a>
        </td>
        <td width="75%" valign="center">
          <p><strong>2023.06 - 2023.10: Research Assistant</strong> at <a href="http://www.liuyebin.com/">Prof. Yebin Liu</a>'s group, Tsinghua University.</p>
          </td>
      </tr> -->

      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/damo.png"><img style="width:100%;max-width:100%" alt="damo" src="images/damo.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2021.08 - 2023.07: Research Intern</strong> in DAMO Academy, Alibaba Group. Mentored by <a href="https://lingzhili.com/">Lingzhi Li</a>, Supervised by <a href="https://lishen-shirley.github.io/">Dr. Li Shen</a>.</p>
      </td>

    </tr>

    <!-- <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <a href="images/avar.png"><img style="width:100%;max-width:100%" alt="avar" src="images/avar.png" class="hoverZoomLink"></a>
    </td>
    <td width="75%" valign="center">
      <p><strong>2023.06 - present: (Part-time) Technical Consultant</strong> & Algorithm Engineer in AVAR, a start-up company about metaverse and digital human.</p>
    </td>
    </tr> -->

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/apple.png"><img style="width:50%;max-width:50%" alt="apple" src="images/apple.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2021.07 - 2021.08: Machine Learning Intern</strong> at Apple Inc., Beijing, China.</p>
        </td>
    </tr>
   
    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Education</heading>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div style="display: flex; justify-content: space-between;">
          <a href="images/ellis.png" style="width:48%;">
            <img style="width:100%;max-width:100%" alt="ellis" src="images/ellis.png" class="hoverZoomLink">
          </a>
          <a href="images/unitn.png" style="width:48%;">
            <img style="width:100%;max-width:100%" alt="unitn" src="images/unitn.png" class="hoverZoomLink">
          </a>
        </div>
      </td>
      <td width="75%" valign="center">
        <p><strong>2024.09 - :</strong> ELLIS PhD student at University of Trento, Itlay.
        <br>
        Supervised by <a href="https://paolorota.github.io/">Prof. Paolo Rota</a> and <a href="https://gulvarol.github.io/">Prof. GÃ¼l Varol(ENPC)</a>.
        <br>
        Working on 3D human motion understanding.
        <br>
        </p>
        </td>
    </tr>
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/pku.png"><img style="width:100%;max-width:100%" alt="pku" src="images/pku.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2020.09 - 2023.06:</strong> M.Sc. in Wangxuan Institute of Computer Techonology(WICT) at Peking University, China.
        <br>
        Supervised by <a href="https://www.wict.pku.edu.cn/zlian/">Prof. Zhouhui Lian</a>.
        <br>
        Worked on 3D-aware Generation, Style Transfer, Neural Rendering.
        <br>
        Thesis: 3D-aware Style Transfer based on Neural Radiance Field.
        </p>
        </td>
    </tr>
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/dut.png"><img style="width:100%;max-width:100%" alt="dut" src="images/dut.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2016.09 - 2020.06:</strong> B.Eng. in School of Software at Dalian University of Technology, China.
        <!-- <br>
        Supervised by Prof. Kun Lu and Prof. Shimin Shan.
        <br> -->
        Major in Big Data and Machine Learning.
        </p>
        </td>
    </tr>


 
  </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <li><strong>Volunteer: </strong>SIGGRAPH 2022, ECCV 2024.</li>
            <li><strong>Teaching Assistant: </strong><a href="https://unitn.coursecatalogue.cineca.it/insegnamenti/2025/50802_649472_95796/2025/50802/10876?annoOrdinamento=2025">Introduction to Computer Programming (Python)</a> for master students at CIMeC, University of Trento, Fall 2025.</li>
            <li><strong>Teaching Assistant: </strong><a href="https://sgi.mit.edu/">SGI(Summer Gemoetry Initiative)</a>, Summer 2023.</li>
            <li><strong>Teaching Assistant: </strong><a href="https://www.wict.pku.edu.cn/zlian/course/ENT/index.htm">Elementary Number Theory</a> for undergraduate students at Peking University, Spring 2021.</li>
            <li><strong>Reviewer: </strong>3DV 2026, WACV 2025, CVPR 2025</li>
            <li><strong>Workshop: </strong><a href="https://i-hfm-2025.github.io/I-HFM-2025/">1st-IHFM @ICCV2025</a></li>
            <!-- <li><strong>Reviewer: </strong>IJCV, TAFFC,THMS.</li> -->
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Selected Awards</heading>
          <li>Doctoral Student Scholarship, University of Trento</li>
          <li>Graduate School Scholarship at Peking University, 2022</li>
          <li>Hackathon PKU Competition rank 2/30 (Â¥10,000), 2021</li>
        </td>
      </tr>
    </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Misc</heading>
          <li>ğŸŸ A DDL chaser (usually failed in most cases).</li>
          <li>â›¸ï¸ An animation connoisseur (I like hand-painting and independent animations).</li>
          <li>ğŸš¶ğŸ»â€â™€ï¸ A daydreamer who wants to be an athlete ğŸƒğŸ»â€â™€ï¸âš½ï¸ğŸŠğŸ»â€â™€ï¸. Recently I started my CrossFit trainingğŸ’ªğŸ¼ and half-marathon trainingğŸƒğŸ»â€â™€ï¸ .</li>
          <li>âš½ï¸ Was a member of PKU Women Football Club. Also a founder of our college women's football team.(I'm a fan of Arsenal F.C.ğŸ”«ğŸ”´âšªï¸)</li>
          <li>ğŸ† We are the champion of Inter-faculty Women's Football Competition in Peking University Cup, 2022-2023!!</li>
        </td>
      </tr>
    </tbody></table>


      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <a href="images/emm.jpeg"><img style="width:50%;max-width:50%" alt="research" src="images/emm.jpeg" class="hoverZoomLink"></a>
        </td>
      </tr> -->
    <!-- </tbody></table>  -->

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr></tr>
        <td style="padding:20px;width:0%;vertical-align:middle">
      </td>
      <td style="padding:20px;width:100%;vertical-align:middle">
      <hr style="margin-top:0px">
        <p>Build the bridge between 2D and 3D world. Do some cool research!ğŸ˜</p>
        <p>Last modified: 30/07/2025</p>
        </td>
      </tr>
    </tbody></table>

</body>
</html>
