<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Shiyao Xu">
  <meta name="description" content="Shiyao Xu's Homepage">
  <meta name="keywords" content="Shiyao Xu,ÂæêËØóÁë∂,homepage,‰∏ªÈ°µ,master,computer vision,Peking University,Alibaba,image generation,texture synthesis,3D reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Shiyao Xu (ÂæêËØóÁë∂)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shiyao Xu (ÂæêËØóÁë∂)</name>
              </p>
              <p style="text-align:center">
                Email: xusy[at]stu.pku.edu.cn/xsy9915[at]gmail.com &nbsp;&nbsp;<a href="https://github.com/41xu">Github</a>&nbsp;&nbsp;<a href="https://xusy2333.com/blog/">Blog</a>&nbsp;&nbsp;<a href="https://www.zhihu.com/people/zhuo-ji-dui-chang">Zhihu</a>
              </p>
              <p>
                I am Shiyao Xu (ÂæêËØóÁë∂), currently a second year master student in <a href="https://www.icst.pku.edu.cn/">Wangxuan Institute of Computer Techonology(WICT, former ICST)</a> at <a href="https://www.pku.edu.cn/">Peking University</a>, supervised by <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>. 
                I'm a member of <a href="http://59.108.48.27/cscl/">CSCL group</a> led by <a href="https://www.wict.pku.edu.cn/zlian/">Prof. Zhouhui Lian</a>, and also a member of <a href="https://damo.alibaba.com/labs/xr-lab">XR-Lab</a> at <a href="https://damo.alibaba.com/">DAMO</a>, Alibaba Inc. 
                I currently work closely with <a href="https://scholar.google.co.uk/citations?user=ABbCaxsAAAAJ&hl=en">Dr. Li Shen</a> and <a href="https://lingzhili.com/">Lingzhi Li</a>. 
              
              </p>
              <p>
                I did my bachelors at <a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>, 2020. <strong>I am looking for a PhD position at 2023 Fall.</strong> Please freely contact me without any hesitation! :)
              </p>
              <p>
                My research interests lie in 3D reconstruction, 3D-aware image synthesis and neural rendering.
              </p>
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/Shiyao_Xu_Cartoon.PNG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Shiyao_Xu_Cartoon.PNG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Experiences</heading>
            <li><font color=red>[News!]</font>Happy to announce that I'll serve as a Student Volunteer (virtual) in SIGGRAPH2022!ü§™</li>
            <li>2021.08-2022.04: Research Intern at XR-Lab, DAMO Academy, Alibaba Inc, supervised by Dr. Li Shen.</li>
            <li>2021.07-2021.08: Machine Learning Intern at Apple, Beijing.</li>
            <li>TA of Elementary Number Theory, Spring 2021</li>
            <li>‚öΩÔ∏è A member of PKU Women Football Club. Also a founder of our college women's football team.(I'm also a fan of Arsenal F.C.üî´)</li>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                  <source src='images/2-teaser.mp4'>
                </video>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Your3dEmoji: Creating Personalized Emojis via One-shot 3D-aware Cartoon Avatar Synthesis</papertitle>
              <br>
              <strong><a href="https://xusy2333.com">Shiyao Xu</a></strong>, <a href="https://lingzhili.com/">Lingzhi Li</a>,  <a href="https://scholar.google.co.uk/citations?user=ABbCaxsAAAAJ&hl=en">Li Shen</a>, <a href="https://menyifang.github.io/">Yifang Men</a>, <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>Under Review</em>
              <p>We propose a novel 3D generative model to translate a real-world face image into its corresponding 3D avatar with only a single style example provided. Our model is 3D-aware in sense and also able to do attribute editing, such as smile, age, etc directly in the 3D domain.</p>
          </td>
      </tr>
          
        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                  <source src='images/1-teaser.mp4'>
                </video>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Dynamic Texture Transfer using PatchMatch and Transformers</papertitle>
              <br>
              Guo Pu*, <strong>Shiyao Xu*</strong>, <a href="https://www.wict.pku.edu.cn/zlian/">Zhouhui Lian</a>
              <br>
              <em>Under Review</em>
              <p>We propose an automatically method to transfer the dynamic texture of a given video to a still image.</p>
              <details>
                <summary>Abstract</summary>
                <ol>
                How to automatically transfer the dynamic texture of a given video to the target still image is a challenging and ongoing problem. 
                In this paper, we propose to handle this task via a simple yet effective model that utilizes both PatchMatch and Transformers. 
                The key idea is to decompose the task of dynamic texture transfer into two stages, where the start frame of the target video with the desired dynamic texture is synthesized in the first stage via a distance map guided texture transfer module based on the PatchMatch algorithm. 
                Then, in the second stage, the synthesized image is decomposed into structure-agnostic patches, according to which their corresponding subsequent patches can be predicted by exploiting the powerful capability of Transformers equipped with VQ-VAE for processing long discrete sequences. 
                After getting all those patches, we apply a Gaussian weighted average merging strat- egy to smoothly assemble them into each frame of the target stylized video. Experimental results demonstrate the effectiveness and superiority of the proposed method in dynamic texture transfer compared to the state of the art.
                </ol>
              </details>
          </td>
      </tr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <a href="images/emm.jpeg"><img style="width:50%;max-width:50%" alt="research" src="images/emm.jpeg" class="hoverZoomLink"></a>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr></tr>
        <td style="padding:20px;width:0%;vertical-align:middle">
      </td>
      <td style="padding:20px;width:100%;vertical-align:middle">
      <hr style="margin-top:0px">
        <p>Build the bridge between 2D and 3D world. Do some cool research!üòé</p>
        <p>Last modified: 17/08/2022</p>
        </td>
      </tr>




        <!-- <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <img src="images/DynTexture.gif" style="width:100%;max-width:100%; position: absolute;top: -5%">
              </div>
          </td>
           
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Dynamic Texture Transfer using PatchMatch and Transformers</papertitle>
              <br>
              Guo Pu*, <strong>Shiyao Xu*</strong>, Zhouhui Lian
              <br>
              <em>under-review</em>
              <p>We propose an automatically method to transfer the dynamic texture of a given video to a still image. </p>
          </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="images/emm.jpeg"><img style="width:100%;max-width:100%" alt="research" src="images/emm.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>



      </td>
    </tr>
  </table>
</body>

</html>
